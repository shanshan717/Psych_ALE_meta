{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载必要的包\n",
    "from os import makedirs, path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from nibabel import save\n",
    "from nilearn import image, plotting, reporting\n",
    "from nimare import correct, io, meta, utils #主要用nimare完成元分析\n",
    "from scipy.stats import norm\n",
    "\n",
    "# We are now ready to perform the actual ALE analyses with NiMARE. \n",
    "# We write a custom function which takes a single Sleuth text file as its input and (a) calculates the ALE map, \n",
    "# (b) corrects for multiple comparisons using a Monte Carlo-based FWE correction, \n",
    "# and (c) stores the cluster level-thresholded maps into the output directory. \n",
    "# We then apply this function to all the Sleuth files we have created in the previous step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.correct:Using correction method implemented in Estimator: nimare.meta.cbma.ale.ALE.correct_fwe_montecarlo.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f620679b0734bfcb01e08033a0fa31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.meta.cbma.base:Using null distribution for voxel-level FWE correction.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/nilearn/image/image.py:1106: UserWarning: Data array used to create a new image contains 64-bit ints. This is likely due to creating the array with numpy and passing `int` as the `dtype`. Many tools such as FSL and SPM cannot deal with int64 in Nifti images, so for compatibility the data has been converted to int32.\n",
      "  return new_img_like(niimg, result, niimg.affine)\n"
     ]
    }
   ],
   "source": [
    "# Define function for performing a single ALE analysis with FWE correction\n",
    "def run_ale(text_file, voxel_thresh, cluster_thresh, random_seed, n_iters, output_dir):\n",
    "\n",
    "    # Set a random seed to make the results reproducible\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Perform the ALE\n",
    "    dset = io.convert_sleuth_to_dataset(text_file=text_file, target=\"mni152_2mm\")\n",
    "    ale = meta.cbma.ALE()\n",
    "    res = ale.fit(dset)\n",
    "\n",
    "    # FWE correction for multiple comparisons\n",
    "    corr = correct.FWECorrector(\n",
    "        method=\"montecarlo\", voxel_thresh=voxel_thresh, n_iters=n_iters\n",
    "    )\n",
    "    cres = corr.transform(result=res)\n",
    "\n",
    "    # Save maps to the ouput directory\n",
    "    prefix = path.basename(text_file).replace(\".txt\", \"\")\n",
    "    res.save_maps(output_dir=output_dir, prefix=prefix)\n",
    "    cres.save_maps(output_dir=output_dir, prefix=prefix)\n",
    "\n",
    "    # Create cluster-level thresholded z and ALE maps\n",
    "    img_clust_mass = cres.get_map(\"z_desc-mass_level-cluster_corr-FWE_method-montecarlo\")\n",
    "    img_clust_size = cres.get_map(\"z_desc-size_level-cluster_corr-FWE_method-montecarlo\")\n",
    "    img_z = cres.get_map(\"z\")\n",
    "    img_ale = cres.get_map(\"stat\")\n",
    "    cluster_thresh_z = norm.ppf(1 - cluster_thresh / 2)\n",
    "    img_clust_mass_thresh = image.threshold_img(img=img_clust_mass, threshold=cluster_thresh_z)\n",
    "    img_clust_size_thresh = image.threshold_img(img=img_clust_size, threshold=cluster_thresh_z)\n",
    "    img_mask = image.math_img(\"np.where(img > 0, 1, 0)\", img=img_clust_size_thresh)\n",
    "    #img_z_thresh = image.math_img(\"img1 * img2\", img1=img_mask, img2=img_z)\n",
    "    img_ale_thresh = image.math_img(\"img1 * img2\", img1=img_mask, img2=img_ale)\n",
    "\n",
    "    # Save thresholded maps to the output directory\n",
    "    save(img=img_clust_mass_thresh, filename=output_dir + \"/\" + prefix + \"_z_mass_level_thresh.nii.gz\")\n",
    "    save(img=img_clust_size_thresh, filename=output_dir + \"/\" + prefix + \"_z_size_level_thresh.nii.gz\")\n",
    "    # Save ALE thresholded for tables later on\n",
    "    save(img=img_ale_thresh, filename=output_dir + \"/\" + prefix + \"_stat_size_thresh.nii.gz\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # Apply our function to all the Sleuth files\n",
    "#         run_ale(\n",
    "#             text_file='/Users/ss/Documents/Psych_ALE_meta/data/Self_all.txt','/Users/ss/Documents/Psych_ALE_meta/data/Self_st.txt'\n",
    "#             voxel_thresh=0.001,\n",
    "#             cluster_thresh=0.05,\n",
    "#             random_seed=1234,\n",
    "#             n_iters=10000,\n",
    "#             output_dir=\"../results/ale/\",\n",
    "#         )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 定义一个包含所有文本文件路径的列表\n",
    "    all_files = [\n",
    "        # '/Users/ss/Documents/Psych_ALE_meta/data/Self_all.txt',\n",
    "        # '/Users/ss/Documents/Psych_ALE_meta/data/Self_st.txt',\n",
    "        '/Users/ss/Documents/Psych_ALE_meta/data/unhealth.txt',\n",
    "        # '/Users/ss/Documents/Psych_ALE_meta/data/health.txt'\n",
    "    ]\n",
    "\n",
    "    # 循环遍历每个文件，依次运行 ALE 分析\n",
    "    for text_file in all_files:\n",
    "        run_ale(\n",
    "            text_file=text_file,\n",
    "            voxel_thresh=0.001,\n",
    "            cluster_thresh=0.05,\n",
    "            random_seed=1234,\n",
    "            n_iters=5000,\n",
    "            output_dir=\"../results/ale/\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
