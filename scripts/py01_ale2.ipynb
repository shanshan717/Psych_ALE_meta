{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载必要的包\n",
    "from os import makedirs, path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from nibabel import save\n",
    "from nilearn import image, plotting, reporting\n",
    "from nimare import correct, io, meta, utils #主要用nimare完成元分析\n",
    "from scipy.stats import norm\n",
    "\n",
    "# We are now ready to perform the actual ALE analyses with NiMARE. \n",
    "# We write a custom function which takes a single Sleuth text file as its input and (a) calculates the ALE map, \n",
    "# (b) corrects for multiple comparisons using a Monte Carlo-based FWE correction, \n",
    "# and (c) stores the cluster level-thresholded maps into the output directory. \n",
    "# We then apply this function to all the Sleuth files we have created in the previous step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.correct:Using correction method implemented in Estimator: nimare.meta.cbma.ale.ALE.correct_fwe_montecarlo.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b482a2fad31459481fce1be48d87a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 46\u001b[0m\n\u001b[1;32m     40\u001b[0m     save(img\u001b[38;5;241m=\u001b[39mimg_ale_thresh, filename\u001b[38;5;241m=\u001b[39moutput_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_stat_size_thresh.nii.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Apply our function to all the Sleuth files\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m         run_ale(\n\u001b[1;32m     47\u001b[0m             text_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/ss/Documents/Psych_ALE_meta/data/Self_all.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     48\u001b[0m             voxel_thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m     49\u001b[0m             cluster_thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m     50\u001b[0m             random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m,\n\u001b[1;32m     51\u001b[0m             n_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[1;32m     52\u001b[0m             output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../results/ale/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m, in \u001b[0;36mrun_ale\u001b[0;34m(text_file, voxel_thresh, cluster_thresh, random_seed, n_iters, output_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# FWE correction for multiple comparisons\u001b[39;00m\n\u001b[1;32m     14\u001b[0m corr \u001b[38;5;241m=\u001b[39m correct\u001b[38;5;241m.\u001b[39mFWECorrector(\n\u001b[1;32m     15\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmontecarlo\u001b[39m\u001b[38;5;124m\"\u001b[39m, voxel_thresh\u001b[38;5;241m=\u001b[39mvoxel_thresh, n_iters\u001b[38;5;241m=\u001b[39mn_iters\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m cres \u001b[38;5;241m=\u001b[39m corr\u001b[38;5;241m.\u001b[39mtransform(result\u001b[38;5;241m=\u001b[39mres)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Save maps to the ouput directory\u001b[39;00m\n\u001b[1;32m     20\u001b[0m prefix \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mbasename(text_file)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nimare/correct.py:186\u001b[0m, in \u001b[0;36mCorrector.transform\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(est, correction_method):\n\u001b[1;32m    182\u001b[0m     LGR\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing correction method implemented in Estimator: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mest\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mest\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrection_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m     )\n\u001b[0;32m--> 186\u001b[0m     corr_maps, corr_tables, description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(est, correction_method)(\n\u001b[1;32m    187\u001b[0m         result, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_inputs(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nimare/meta/cbma/base.py:727\u001b[0m, in \u001b[0;36mCBMAEstimator.correct_fwe_montecarlo\u001b[0;34m(self, result, voxel_thresh, n_iters, n_cores, vfwe_only)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# Define connectivity matrix for cluster labeling\u001b[39;00m\n\u001b[1;32m    725\u001b[0m conn \u001b[38;5;241m=\u001b[39m ndimage\u001b[38;5;241m.\u001b[39mgenerate_binary_structure(rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, connectivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 727\u001b[0m perm_results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    728\u001b[0m     r\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    730\u001b[0m         Parallel(return_as\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39mn_cores)(\n\u001b[1;32m    731\u001b[0m             delayed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_correct_fwe_montecarlo_permutation)(\n\u001b[1;32m    732\u001b[0m                 iter_xyzs[i_iter],\n\u001b[1;32m    733\u001b[0m                 iter_df\u001b[38;5;241m=\u001b[39miter_df,\n\u001b[1;32m    734\u001b[0m                 conn\u001b[38;5;241m=\u001b[39mconn,\n\u001b[1;32m    735\u001b[0m                 voxel_thresh\u001b[38;5;241m=\u001b[39mss_thresh,\n\u001b[1;32m    736\u001b[0m                 vfwe_only\u001b[38;5;241m=\u001b[39mvfwe_only,\n\u001b[1;32m    737\u001b[0m             )\n\u001b[1;32m    738\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iters)\n\u001b[1;32m    739\u001b[0m         ),\n\u001b[1;32m    740\u001b[0m         total\u001b[38;5;241m=\u001b[39mn_iters,\n\u001b[1;32m    741\u001b[0m     )\n\u001b[1;32m    742\u001b[0m ]\n\u001b[1;32m    744\u001b[0m fwe_voxel_max, fwe_cluster_size_max, fwe_cluster_mass_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mperm_results)\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vfwe_only:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;66;03m# Cluster-level FWE\u001b[39;00m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;66;03m# Extract the summary statistics in voxel-wise (3D) form, threshold, and\u001b[39;00m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;66;03m# cluster-label\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nimare/meta/cbma/base.py:577\u001b[0m, in \u001b[0;36mCBMAEstimator._correct_fwe_montecarlo_permutation\u001b[0;34m(self, iter_xyz, iter_df, conn, voxel_thresh, vfwe_only)\u001b[0m\n\u001b[1;32m    572\u001b[0m iter_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m iter_xyz\n\u001b[1;32m    574\u001b[0m iter_ma_maps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_transformer\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m    575\u001b[0m     iter_df, masker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m )\n\u001b[0;32m--> 577\u001b[0m iter_ss_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_summarystat(iter_ma_maps)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m iter_ma_maps\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# Voxel-level inference\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nimare/meta/cbma/base.py:274\u001b[0m, in \u001b[0;36mCBMAEstimator._compute_summarystat\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported data type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# Apply weights before returning\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_summarystat_est(ma_values)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nimare/meta/cbma/ale.py:208\u001b[0m, in \u001b[0;36mALE._compute_summarystat_est\u001b[0;34m(self, ma_values)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_summarystat_est\u001b[39m(\u001b[38;5;28mself\u001b[39m, ma_values):\n\u001b[0;32m--> 208\u001b[0m     stat_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m ma_values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# np.array type is used by _determine_histogram_bins to calculate max_poss_ale\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stat_values, sparse\u001b[38;5;241m.\u001b[39m_coo\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mCOO):\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;66;03m# NOTE: This may not work correctly with a non-NiftiMasker.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sparse/_sparse_array.py:283\u001b[0m, in \u001b[0;36mSparseArray.__array_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sparse_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39msuppress(\u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m    286\u001b[0m     sparse_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sparse/_common.py:2130\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(x, axis, dtype, keepdims)\u001b[0m\n\u001b[1;32m   2129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprod\u001b[39m(x, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mprod(axis\u001b[38;5;241m=\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sparse/_sparse_array.py:571\u001b[0m, in \u001b[0;36mSparseArray.prod\u001b[0;34m(self, axis, keepdims, dtype, out)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprod\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    Performs a product operation along the given axes. Uses all axes by default.\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    :obj:`numpy.prod` : Equivalent numpy function.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmultiply\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, out\u001b[38;5;241m=\u001b[39mout, axis\u001b[38;5;241m=\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sparse/_sparse_array.py:342\u001b[0m, in \u001b[0;36mSparseArray.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m     result \u001b[38;5;241m=\u001b[39m elemwise(ufunc, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 342\u001b[0m     result \u001b[38;5;241m=\u001b[39m SparseArray\u001b[38;5;241m.\u001b[39m_reduce(ufunc, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sparse/_sparse_array.py:307\u001b[0m, in \u001b[0;36mSparseArray._reduce\u001b[0;34m(method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ss\u001b[38;5;241m.\u001b[39mspmatrix):\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_scipy_sparse(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sparse/_sparse_array.py:407\u001b[0m, in \u001b[0;36mSparseArray.reduce\u001b[0;34m(self, method, axis, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     data \u001b[38;5;241m=\u001b[39m method(\n\u001b[1;32m    402\u001b[0m         data,\n\u001b[1;32m    403\u001b[0m         reduce_super_ufunc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value, n_cols \u001b[38;5;241m-\u001b[39m counts),\n\u001b[1;32m    404\u001b[0m     )\u001b[38;5;241m.\u001b[39mastype(data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    405\u001b[0m     result_fill_value \u001b[38;5;241m=\u001b[39m reduce_super_ufunc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value, n_cols)\n\u001b[0;32m--> 407\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce_return(data, arr_attrs, result_fill_value)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n\u001b[1;32m    410\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sparse/_coo/core.py:720\u001b[0m, in \u001b[0;36mCOO._reduce_return\u001b[0;34m(self, data, arr_attrs, result_fill_value)\u001b[0m\n\u001b[1;32m    709\u001b[0m coords \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcoords[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, inv_idx]\n\u001b[1;32m    710\u001b[0m out \u001b[38;5;241m=\u001b[39m COO(\n\u001b[1;32m    711\u001b[0m     coords,\n\u001b[1;32m    712\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    717\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mresult_fill_value,\n\u001b[1;32m    718\u001b[0m )\n\u001b[0;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[d] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m neg_axis))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sparse/_coo/core.py:1050\u001b[0m, in \u001b[0;36mCOO.reshape\u001b[0;34m(self, shape, order)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(shape[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m   1049\u001b[0m     coords[\u001b[38;5;241m-\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), :] \u001b[38;5;241m=\u001b[39m (linear_loc \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m strides) \u001b[38;5;241m%\u001b[39m d\n\u001b[0;32m-> 1050\u001b[0m     strides \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m d\n\u001b[1;32m   1052\u001b[0m result \u001b[38;5;241m=\u001b[39m COO(\n\u001b[1;32m   1053\u001b[0m     coords,\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1059\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value,\n\u001b[1;32m   1060\u001b[0m )\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define function for performing a single ALE analysis with FWE correction\n",
    "def run_ale(text_file, voxel_thresh, cluster_thresh, random_seed, n_iters, output_dir):\n",
    "\n",
    "    # Set a random seed to make the results reproducible\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Perform the ALE\n",
    "    dset = io.convert_sleuth_to_dataset(text_file=text_file, target=\"mni152_2mm\")\n",
    "    ale = meta.cbma.ALE()\n",
    "    res = ale.fit(dset)\n",
    "\n",
    "    # FWE correction for multiple comparisons\n",
    "    corr = correct.FWECorrector(\n",
    "        method=\"montecarlo\", voxel_thresh=voxel_thresh, n_iters=n_iters\n",
    "    )\n",
    "    cres = corr.transform(result=res)\n",
    "\n",
    "    # Save maps to the ouput directory\n",
    "    prefix = path.basename(text_file).replace(\".txt\", \"\")\n",
    "    res.save_maps(output_dir=output_dir, prefix=prefix)\n",
    "    cres.save_maps(output_dir=output_dir, prefix=prefix)\n",
    "\n",
    "    # Create cluster-level thresholded z and ALE maps\n",
    "    img_clust_mass = cres.get_map(\"z_desc-mass_level-cluster_corr-FWE_method-montecarlo\")\n",
    "    img_clust_size = cres.get_map(\"z_desc-size_level-cluster_corr-FWE_method-montecarlo\")\n",
    "    img_z = cres.get_map(\"z\")\n",
    "    img_ale = cres.get_map(\"stat\")\n",
    "    cluster_thresh_z = norm.ppf(1 - cluster_thresh / 2)\n",
    "    img_clust_mass_thresh = image.threshold_img(img=img_clust_mass, threshold=cluster_thresh_z)\n",
    "    img_clust_size_thresh = image.threshold_img(img=img_clust_size, threshold=cluster_thresh_z)\n",
    "    img_mask = image.math_img(\"np.where(img > 0, 1, 0)\", img=img_clust_size_thresh)\n",
    "    #img_z_thresh = image.math_img(\"img1 * img2\", img1=img_mask, img2=img_z)\n",
    "    img_ale_thresh = image.math_img(\"img1 * img2\", img1=img_mask, img2=img_ale)\n",
    "\n",
    "    # Save thresholded maps to the output directory\n",
    "    save(img=img_clust_mass_thresh, filename=output_dir + \"/\" + prefix + \"_z_mass_level_thresh.nii.gz\")\n",
    "    save(img=img_clust_size_thresh, filename=output_dir + \"/\" + prefix + \"_z_size_level_thresh.nii.gz\")\n",
    "    # Save ALE thresholded for tables later on\n",
    "    save(img=img_ale_thresh, filename=output_dir + \"/\" + prefix + \"_stat_size_thresh.nii.gz\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # Apply our function to all the Sleuth files\n",
    "#         run_ale(\n",
    "#             text_file='/Users/ss/Documents/Psych_ALE_meta/data/Self_all.txt','/Users/ss/Documents/Psych_ALE_meta/data/Self_st.txt'\n",
    "#             voxel_thresh=0.001,\n",
    "#             cluster_thresh=0.05,\n",
    "#             random_seed=1234,\n",
    "#             n_iters=10000,\n",
    "#             output_dir=\"../results/ale/\",\n",
    "#         )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 定义一个包含所有文本文件路径的列表\n",
    "    all_files = [\n",
    "        '/Users/ss/Documents/Psych_ALE_meta/data/health<unhealth.txt',\n",
    "        '/Users/ss/Documents/Psych_ALE_meta/data/health>unhealth.txt'\n",
    "    ]\n",
    "\n",
    "    # 循环遍历每个文件，依次运行 ALE 分析\n",
    "    for text_file in all_files:\n",
    "        run_ale(\n",
    "            text_file=text_file,\n",
    "            voxel_thresh=0.001,\n",
    "            cluster_thresh=0.05,\n",
    "            random_seed=1234,\n",
    "            n_iters=10000,\n",
    "            output_dir=\"../results/ale/\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Finally, let's look at some exemplary results by plotting the (cluster-level FWE-corrected) *z* score map from the main analysis (including all semantic experiments). We also print a table of the corresponding cluster statistics.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Glass brain example\n",
    "    img = image.load_img(\"data/Self_all_z_desc-size_level-cluster_corr-FWE_method-montecarlo.nii.gz\")\n",
    "    p = plotting.plot_glass_brain(img, display_mode=\"lyrz\", colorbar=True)\n",
    "\n",
    "    # Cluster table example\n",
    "    t = reporting.get_clusters_table(img, stat_threshold=0, min_distance=1000)\n",
    "    display(t)\n",
    "\n",
    "    print(cres.maps.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保输出目录存在\n",
    "output_dir = \"/Users/ss/Documents/Psych_ALE_meta/results/ale/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义运行 ALE 分析的函数\n",
    "def run_ale(text_file, voxel_thresh, cluster_thresh, random_seed, n_iters, output_dir):\n",
    "    # 设置随机种子\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    # 加载 Sleuth 文件并进行 ALE 分析\n",
    "    dset = io.convert_sleuth_to_dataset(text_file=text_file, target=\"ale_2mm\")\n",
    "    ale = meta.cbma.ALE()\n",
    "    res = ale.fit(dset)\n",
    "\n",
    "    # 使用蒙特卡洛方法进行 FWE 校正\n",
    "    corr = correct.FWECorrector(\n",
    "        method=\"montecarlo\", voxel_thresh=voxel_thresh, n_iters=n_iters\n",
    "    )\n",
    "    cres = corr.transform(result=res)\n",
    "\n",
    "    # 保存未阈值化的 z 和 ALE 映射\n",
    "    prefix = os.path.basename(text_file).replace(\".txt\", \"\")\n",
    "    res.save_maps(output_dir=output_dir, prefix=prefix)\n",
    "    cres.save_maps(output_dir=output_dir, prefix=prefix)\n",
    "\n",
    "    # 生成集群级阈值化的 z 和 ALE 映射\n",
    "    img_clust = cres.get_map(\"z_level-cluster_corr-FWE_method-montecarlo\")\n",
    "    img_z = cres.get_map(\"z\")\n",
    "    img_ale = cres.get_map(\"stat\")\n",
    "    cluster_thresh_z = norm.ppf(1 - cluster_thresh / 2)\n",
    "    img_clust_thresh = image.threshold_img(img=img_clust, threshold=cluster_thresh_z)\n",
    "    img_mask = image.math_img(\"np.where(img > 0, 1, 0)\", img=img_clust_thresh)\n",
    "    img_z_thresh = image.math_img(\"img1 * img2\", img1=img_mask, img2=img_z)\n",
    "    img_ale_thresh = image.math_img(\"img1 * img2\", img1=img_mask, img2=img_ale)\n",
    "\n",
    "    # 保存阈值化的映射\n",
    "    save(img=img_z_thresh, filename=os.path.join(output_dir, prefix + \"_z_thresh.nii.gz\"))\n",
    "    save(img=img_ale_thresh, filename=os.path.join(output_dir, prefix + \"_stat_thresh.nii.gz\"))\n",
    "\n",
    "    print(f\"Analysis complete for '{text_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.correct:Using correction method implemented in Estimator: nimare.meta.cbma.ale.ALE.correct_fwe_montecarlo.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63c98071ba140338d639adb95dda98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.meta.cbma.base:Using null distribution for voxel-level FWE correction.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No map with name 'z_level-cluster_corr-FWE_method-montecarlo' found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 执行 ALE 分析\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m run_ale(\n\u001b[1;32m      3\u001b[0m     text_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/ss/Documents/Psych_ALE_meta/data/Self_all.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     voxel_thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      5\u001b[0m     cluster_thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m      6\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m,\n\u001b[1;32m      7\u001b[0m     n_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      8\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir\n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[13], line 24\u001b[0m, in \u001b[0;36mrun_ale\u001b[0;34m(text_file, voxel_thresh, cluster_thresh, random_seed, n_iters, output_dir)\u001b[0m\n\u001b[1;32m     21\u001b[0m cres\u001b[38;5;241m.\u001b[39msave_maps(output_dir\u001b[38;5;241m=\u001b[39moutput_dir, prefix\u001b[38;5;241m=\u001b[39mprefix)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 生成集群级阈值化的 z 和 ALE 映射\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m img_clust \u001b[38;5;241m=\u001b[39m cres\u001b[38;5;241m.\u001b[39mget_map(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz_level-cluster_corr-FWE_method-montecarlo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m img_z \u001b[38;5;241m=\u001b[39m cres\u001b[38;5;241m.\u001b[39mget_map(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m img_ale \u001b[38;5;241m=\u001b[39m cres\u001b[38;5;241m.\u001b[39mget_map(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nimare/results.py:132\u001b[0m, in \u001b[0;36mMetaResult.get_map\u001b[0;34m(self, name, return_type)\u001b[0m\n\u001b[1;32m    130\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaps\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo map with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# pending resolution of https://github.com/nilearn/nilearn/issues/2724\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: No map with name 'z_level-cluster_corr-FWE_method-montecarlo' found."
     ]
    }
   ],
   "source": [
    "# 执行 ALE 分析\n",
    "run_ale(\n",
    "    text_file=\"/Users/ss/Documents/Psych_ALE_meta/data/Self_all.txt\",\n",
    "    voxel_thresh=0.001,\n",
    "    cluster_thresh=0.01,\n",
    "    random_seed=1234,\n",
    "    n_iters=100,\n",
    "    output_dir=output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ale(text_file, voxel_thresh, cluster_thresh, random_seed, n_iters, output_dir):\n",
    "\n",
    "    # Let's show the user what we are doing\n",
    "    # 显示当前操作的信息\n",
    "    print(\"ALE ANALYSIS FOR '\" + text_file + \"' WITH \" + str(n_iters) + \" PERMUTATIONS\")\n",
    "\n",
    "    # Set a random seed to make the results reproducible\n",
    "    # 设置随机种子以使结果可重现\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Perform the ALE\n",
    "    # 执行ALE分析\n",
    "    # 使用io.convert_sleuth_to_dataset函数将Sleuth格式的数据转换为ALE分析所需的数据集。\n",
    "    dset = io.convert_sleuth_to_dataset(text_file=text_file, target=\"ale_2mm\") # 这里的target是指定的空间模板，可以是MNI152_2mm\n",
    "    # 创建ALE分析对象`ale`\n",
    "    ale = meta.cbma.ALE()\n",
    "    # 使用`ale.fit`方法对数据集进行拟合\n",
    "    res = ale.fit(dset)\n",
    "\n",
    "    # FWE correction for multiple comparisons\n",
    "    # 多重比较的FWE校正\n",
    "    corr = correct.FWECorrector(\n",
    "        method=\"montecarlo\", voxel_thresh=voxel_thresh, n_iters=n_iters\n",
    "    )\n",
    "    cres = corr.transform(result=res)\n",
    "\n",
    "    # Save unthresholded maps to the ouput directory\n",
    "    # 将未阈值化的地图保存到输出目录\n",
    "    prefix = path.basename(text_file).replace(\".txt\", \"\")\n",
    "    res.save_maps(output_dir=output_dir, prefix=prefix)\n",
    "    cres.save_maps(output_dir=output_dir, prefix=prefix)\n",
    "\n",
    "    # Create cluster-level thresholded z and ALE maps\n",
    "    # 创建集群级阈值化的z和ALE地图\n",
    "    img_clust = cres.get_map(\"z_level-cluster_corr-FWE_method-montecarlo\")\n",
    "    img_z = cres.get_map(\"z\")\n",
    "    img_ale = cres.get_map(\"stat\")\n",
    "\n",
    "    # 计算cluster阈值的z值 \n",
    "    cluster_thresh_z = norm.ppf(1 - cluster_thresh / 2) \n",
    "    # 使用`image.threshold_img`函数对cluster图像进行阈值化\n",
    "    img_clust_thresh = image.threshold_img(img=img_clust, threshold=cluster_thresh_z)\n",
    "\n",
    "    # Create thresholded z and ALE maps\n",
    "    # 创建一个掩码图像`img_mask`，其中值大于0的体素被设置为1，其余为0。\n",
    "    img_mask = image.math_img(\"np.where(img > 0, 1, 0)\", img=img_clust_thresh)\n",
    "    img_z_thresh = image.math_img(\"img1 * img2\", img1=img_mask, img2=img_z)\n",
    "    # 使用`image.math_img`方法将掩码应用于z图像和ALE图像，得到阈值化的z图像和ALE图像。\n",
    "    img_ale_thresh = image.math_img(\"img1 * img2\", img1=img_mask, img2=img_ale)\n",
    "\n",
    "    # Save thresholded maps to the output directory\n",
    "    # 保存阈值化的图像\n",
    "    save(img=img_z_thresh, filename=output_dir + \"/\" + prefix + \"_z_thresh.nii.gz\")\n",
    "    save(img=img_ale_thresh, filename=output_dir + \"/\" + prefix + \"_stat_thresh.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Finally, let's look at some exemplary results by plotting the (cluster-level FWE-corrected) *z* score map from the main analysis (including all semantic experiments). We also print a table of the corresponding cluster statistics.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Glass brain example\n",
    "    img = image.load_img(\"data/health_z.nii.gz\")\n",
    "    p = plotting.plot_glass_brain(img, display_mode=\"lyrz\", colorbar=True)\n",
    "\n",
    "    # Cluster table example\n",
    "    t = reporting.get_clusters_table(img, stat_threshold=0, min_distance=1000)\n",
    "    display(t)\n",
    "\n",
    "    print(cres.maps.keys())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
